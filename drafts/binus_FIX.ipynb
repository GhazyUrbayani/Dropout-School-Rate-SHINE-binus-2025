{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LncpgCideHf"
      },
      "outputs": [],
      "source": [
        "# GradientBoosting 3.7327  MinMaxScaler MeanImputer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Memuat Data ---\n",
        "try:\n",
        "    train_df = pd.read_csv('train_dataset.csv')\n",
        "    test_df = pd.read_csv('test_dataset.csv')\n",
        "    print(\"Data berhasil dimuat.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Gagal memuat file. Pastikan 'train_dataset.csv' dan 'test_dataset.csv' ada. Detail: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Persiapan Data ---\n",
        "train_df.dropna(subset=['dropout_rate_percent'], inplace=True)\n",
        "X_train = train_df.drop('dropout_rate_percent', axis=1)\n",
        "y_train = train_df['dropout_rate_percent']\n",
        "X_test = test_df.copy()\n",
        "categorical_features_pre_fe = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- 3. Definisi Feature Engineering Transformer ---\n",
        "class SelectableFeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, include_features=None):\n",
        "        self.include_features = include_features if include_features is not None else []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        # Selalu buat semua fitur yang mungkin dibutuhkan oleh pipeline\n",
        "        df['funding_per_teacher'] = df['funding_per_student_usd'] * df['student_teacher_ratio']\n",
        "        df['low_income_minority_interaction'] = df['percent_low_income'] * df['percent_minority']\n",
        "        df['score_to_funding_ratio'] = df['avg_test_score_percent'] / (df['funding_per_student_usd'] + 1e-6)\n",
        "        df['is_high_school'] = df['school_name'].str.contains('High', case=False, na=False).astype(int)\n",
        "        df['is_middle_school'] = df['school_name'].str.contains('Middle', case=False, na=False).astype(int)\n",
        "        df['is_elementary_school'] = df['school_name'].str.contains('Elementary', case=False, na=False).astype(int)\n",
        "        df['minority_to_internet_gap'] = df['percent_minority'] - df['internet_access_percent']\n",
        "        return df\n",
        "\n",
        "# --- 4. Membangun Pipeline Spesifik ---\n",
        "print(\"Membangun pipeline dengan konfigurasi yang ditentukan...\")\n",
        "\n",
        "# Konfigurasi yang ditentukan\n",
        "specific_features = [\n",
        "    'is_high_school', 'is_middle_school', 'is_elementary_school', 'funding_per_teacher',\n",
        "    'low_income_minority_interaction', 'score_to_funding_ratio', 'minority_to_internet_gap'\n",
        "]\n",
        "\n",
        "# Tentukan fitur numerik berdasarkan data awal + fitur rekayasa\n",
        "# Ini cara aman untuk memastikan semua kolom ada\n",
        "all_possible_new_features = [\n",
        "    'funding_per_teacher', 'low_income_minority_interaction', 'score_to_funding_ratio',\n",
        "    'is_high_school', 'is_middle_school', 'is_elementary_school', 'minority_to_internet_gap'\n",
        "]\n",
        "initial_numerical_features = X_train.select_dtypes(include=np.number).columns.drop('id', errors='ignore').tolist()\n",
        "final_numerical_features = initial_numerical_features + all_possible_new_features\n",
        "\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_features_to_encode = [col for col in categorical_features_pre_fe if col != 'school_name']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, final_numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features_to_encode)\n",
        "    ],\n",
        "    remainder='drop' # Hanya gunakan fitur yang sudah didefinisikan\n",
        ")\n",
        "\n",
        "# Definisikan pipeline final\n",
        "final_pipeline = Pipeline(steps=[\n",
        "    ('feature_engineering', SelectableFeatureEngineeringTransformer(include_features=specific_features)),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# --- 5. Melatih Model dan Membuat Prediksi ---\n",
        "print(\"Melatih model final...\")\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Membuat prediksi pada data test...\")\n",
        "final_predictions = final_pipeline.predict(X_test)\n",
        "\n",
        "# --- 6. Membuat File Submission ---\n",
        "submission_df = pd.DataFrame({'id': X_test['id'], 'dropout_rate_percent': final_predictions})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"\\nFile 'submission.csv' berhasil dibuat dengan konfigurasi terbaik.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GradientBoosting 3.6661 Ensemble Optuna ---\n",
        "!pip install optuna -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import itertools\n",
        "import optuna\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# --- 1. Setup Awal ---\n",
        "warnings.filterwarnings('ignore')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# --- 2. Memuat Data ---\n",
        "try:\n",
        "    train_df = pd.read_csv('train_dataset.csv')\n",
        "    test_df = pd.read_csv('test_dataset.csv')\n",
        "    print(\"Data berhasil dimuat.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Gagal memuat file. Detail: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Persiapan Data ---\n",
        "train_df.dropna(subset=['dropout_rate_percent'], inplace=True)\n",
        "X_train = train_df.drop('dropout_rate_percent', axis=1)\n",
        "y_train = train_df['dropout_rate_percent']\n",
        "X_test = test_df.copy()\n",
        "categorical_features_pre_fe = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- 4. Definisi Feature Engineering Transformer (Tetap Sama) ---\n",
        "class SelectableFeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, include_features=None):\n",
        "        self.include_features = include_features if include_features is not None else []\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        # ... (Kode FE lengkap disembunyikan untuk keringkasan, tapi tetap sama seperti sebelumnya)\n",
        "        if 'funding_per_teacher' in self.include_features: df['funding_per_teacher'] = df['funding_per_student_usd'] * df['student_teacher_ratio']\n",
        "        if 'low_income_minority_interaction' in self.include_features: df['low_income_minority_interaction'] = df['percent_low_income'] * df['percent_minority']\n",
        "        if 'score_to_funding_ratio' in self.include_features: df['score_to_funding_ratio'] = df['avg_test_score_percent'] / (df['funding_per_student_usd'] + 1e-6)\n",
        "        if 'internet_to_income_ratio' in self.include_features: df['internet_to_income_ratio'] = df['internet_access_percent'] / (df['percent_low_income'] + 1e-6)\n",
        "        if 'is_high_school' in self.include_features: df['is_high_school'] = df['school_name'].str.contains('High', case=False, na=False).astype(int)\n",
        "        if 'is_middle_school' in self.include_features: df['is_middle_school'] = df['school_name'].str.contains('Middle', case=False, na=False).astype(int)\n",
        "        if 'is_elementary_school' in self.include_features: df['is_elementary_school'] = df['school_name'].str.contains('Elementary', case=False, na=False).astype(int)\n",
        "        if 'teacher_load' in self.include_features: df['teacher_load'] = 1 / (df['student_teacher_ratio'] + 1 + 1e-6)\n",
        "        if 'adjusted_funding' in self.include_features: df['adjusted_funding'] = df['funding_per_student_usd'] * (df['internet_access_percent'] / 100)\n",
        "        if 'minority_to_internet_gap' in self.include_features: df['minority_to_internet_gap'] = df['percent_minority'] - df['internet_access_percent']\n",
        "        return df\n",
        "\n",
        "# --- 5. Mendefinisikan Fungsi & Konfigurasi Terbaik untuk Ensemble ---\n",
        "\n",
        "# A. Fungsi untuk membuat pipeline secara dinamis\n",
        "def create_pipeline(config):\n",
        "    # Dapatkan daftar kolom numerik setelah FE\n",
        "    temp_transformer = SelectableFeatureEngineeringTransformer(include_features=config['features'])\n",
        "    temp_df = temp_transformer.transform(X_train.head())\n",
        "    numerical_features_after_fe = temp_df.select_dtypes(include=np.number).columns.drop('id', errors='ignore').tolist()\n",
        "    categorical_features_to_encode = [col for col in categorical_features_pre_fe if col != 'school_name']\n",
        "\n",
        "    numerical_transformer = Pipeline(steps=[('imputer', config['imputer']), ('scaler', config['scaler'])])\n",
        "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
        "    preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_features_after_fe), ('cat', categorical_transformer, categorical_features_to_encode)], remainder='drop')\n",
        "\n",
        "    return Pipeline(steps=[\n",
        "        ('feature_engineering', SelectableFeatureEngineeringTransformer(include_features=config['features'])),\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', config['model'])\n",
        "    ])\n",
        "\n",
        "# B. Top 3 Konfigurasi dari hasil Brute Force\n",
        "top_configs = [\n",
        "    {\n",
        "        'name': 'Config_1_Best',\n",
        "        'features': ['is_high_school', 'is_middle_school', 'is_elementary_school', 'funding_per_teacher', 'low_income_minority_interaction', 'score_to_funding_ratio', 'minority_to_internet_gap'],\n",
        "        'imputer': SimpleImputer(strategy='mean'),\n",
        "        'scaler': MinMaxScaler(),\n",
        "        'model': GradientBoostingRegressor(random_state=42)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config_2_Variant',\n",
        "        'features': ['is_high_school', 'is_middle_school', 'is_elementary_school', 'funding_per_teacher', 'low_income_minority_interaction', 'score_to_funding_ratio', 'minority_to_internet_gap'],\n",
        "        'imputer': SimpleImputer(strategy='mean'),\n",
        "        'scaler': StandardScaler(),\n",
        "        'model': GradientBoostingRegressor(random_state=42)\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config_3_FeatureVariant',\n",
        "        'features': ['is_high_school', 'is_middle_school', 'is_elementary_school', 'funding_per_teacher', 'low_income_minority_interaction', 'score_to_funding_ratio', 'teacher_load', 'minority_to_internet_gap'],\n",
        "        'imputer': SimpleImputer(strategy='mean'),\n",
        "        'scaler': MinMaxScaler(),\n",
        "        'model': GradientBoostingRegressor(random_state=42)\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- 6. Hyperparameter Tuning dengan Optuna pada Konfigurasi Terbaik ---\n",
        "print(\"Memulai Hyperparameter Tuning dengan Optuna...\")\n",
        "\n",
        "def objective(trial):\n",
        "    # Definisikan hyperparameter yang akan di-tuning\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "    }\n",
        "\n",
        "    # Buat pipeline dengan parameter dari Optuna\n",
        "    config = top_configs[0].copy()\n",
        "    config['model'].set_params(**params)\n",
        "    pipeline = create_pipeline(config)\n",
        "\n",
        "    # Lakukan cross-validation dan kembalikan skor MAE\n",
        "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "    return -score.mean()\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "\n",
        "print(\"Tuning Optuna selesai.\")\n",
        "print(f\"MAE terbaik dari CV: {study.best_value:.4f}\")\n",
        "print(\"Parameter terbaik:\", study.best_params)\n",
        "\n",
        "# --- 7. Melatih Ensemble & Membuat Prediksi ---\n",
        "print(\"\\nMelatih model-model dalam ensemble...\")\n",
        "all_predictions = []\n",
        "\n",
        "# Model 1 (Terbaik + Tuned)\n",
        "tuned_config = top_configs[0].copy()\n",
        "tuned_config['model'].set_params(**study.best_params)\n",
        "pipeline_1 = create_pipeline(tuned_config)\n",
        "pipeline_1.fit(X_train, y_train)\n",
        "preds_1 = pipeline_1.predict(X_test)\n",
        "all_predictions.append(preds_1)\n",
        "print(f\"- Model 1 ({tuned_config['name']}) berhasil dilatih.\")\n",
        "\n",
        "# Model 2 dan 3 (Default)\n",
        "for i, config in enumerate(top_configs[1:]):\n",
        "    pipeline = create_pipeline(config)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    preds = pipeline.predict(X_test)\n",
        "    all_predictions.append(preds)\n",
        "    print(f\"- Model {i+2} ({config['name']}) berhasil dilatih.\")\n",
        "\n",
        "# --- 8. Blending dan Membuat Submission ---\n",
        "print(\"\\nMenggabungkan prediksi (blending)...\")\n",
        "ensemble_preds = np.mean(all_predictions, axis=0)\n",
        "\n",
        "submission_df = pd.DataFrame({'id': X_test['id'], 'dropout_rate_percent': ensemble_preds})\n",
        "submission_df.to_csv('submissionTes.csv', index=False)\n",
        "\n",
        "print(\"\\n========================================================\")\n",
        "print(\"File 'submissionTes.csv' berhasil dibuat dari model ensemble.\")\n",
        "print(\"========================================================\")"
      ],
      "metadata": {
        "id": "jtdbHJqlenR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GradientBoosting 3.6587 non-Ensemble (diEnsemble malah Rusak) Grid Search CV ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "# import optuna # Not needed\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
        "\n",
        "# --- 1. Setup Awal ---\n",
        "warnings.filterwarnings('ignore')\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING) # Not needed\n",
        "\n",
        "# --- 2. Memuat Data ---\n",
        "try:\n",
        "    train_df = pd.read_csv('train_dataset.csv')\n",
        "    test_df = pd.read_csv('test_dataset.csv')\n",
        "    print(\"Data berhasil dimuat.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Gagal memuat file. Detail: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Persiapan Data ---\n",
        "train_df.dropna(subset=['dropout_rate_percent'], inplace=True)\n",
        "X_train = train_df.drop('dropout_rate_percent', axis=1)\n",
        "y_train = train_df['dropout_rate_percent']\n",
        "X_test = test_df.copy()\n",
        "categorical_features_pre_fe = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- 4. Definisi Feature Engineering Transformer (Tetap Sama) ---\n",
        "class SelectableFeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, include_features=None):\n",
        "        self.include_features = include_features if include_features is not None else []\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        if 'funding_per_teacher' in self.include_features: df['funding_per_teacher'] = df['funding_per_student_usd'] * df['student_teacher_ratio']\n",
        "        if 'low_income_minority_interaction' in self.include_features: df['low_income_minority_interaction'] = df['percent_low_income'] * df['percent_minority']\n",
        "        if 'score_to_funding_ratio' in self.include_features: df['score_to_funding_ratio'] = df['avg_test_score_percent'] / (df['funding_per_student_usd'] + 1e-6)\n",
        "        if 'internet_to_income_ratio' in self.include_features: df['internet_access_percent'] / (df['percent_low_income'] + 1e-6) # Fixed potential division by zero\n",
        "        if 'is_high_school' in self.include_features: df['is_high_school'] = df['school_name'].str.contains('High', case=False, na=False).astype(int)\n",
        "        if 'is_middle_school' in self.include_features: df['is_middle_school'] = df['school_name'].str.contains('Middle', case=False, na=False).astype(int)\n",
        "        if 'is_elementary_school' in self.include_features: df['is_elementary_school'] = df['school_name'].str.contains('Elementary', case=False, na=False).astype(int)\n",
        "        if 'teacher_load' in self.include_features: df['teacher_load'] = 1 / (df['student_teacher_ratio'] + 1 + 1e-6) # Fixed potential division by zero\n",
        "        if 'adjusted_funding' in self.include_features: df['adjusted_funding'] = df['funding_per_student_usd'] * (df['internet_access_percent'] / 100)\n",
        "        if 'minority_to_internet_gap' in self.include_features: df['minority_to_internet_gap'] = df['percent_minority'] - df['internet_access_percent']\n",
        "        return df\n",
        "\n",
        "# --- 5. Mendefinisikan Pipeline dan Grid untuk Tuning ---\n",
        "\n",
        "# A. Konfigurasi Terbaik dari hasil Brute Force (sesuaikan jika hasil brute force Anda berbeda)\n",
        "# Menggunakan konfigurasi terbaik yang sering muncul: GradientBoosting, MeanImputer, MinMaxScaler, dengan fitur spesifik\n",
        "base_config = {\n",
        "    'features': ['is_high_school', 'is_middle_school', 'is_elementary_school', 'funding_per_teacher', 'low_income_minority_interaction', 'score_to_funding_ratio', 'minority_to_internet_gap'],\n",
        "    'imputer': SimpleImputer(strategy='mean'),\n",
        "    'scaler': MinMaxScaler(),\n",
        "}\n",
        "\n",
        "# B. Buat pipeline dasar dengan konfigurasi terbaik\n",
        "# Dapatkan daftar kolom numerik setelah FE untuk konfigurasi dasar\n",
        "temp_transformer = SelectableFeatureEngineeringTransformer(include_features=base_config['features'])\n",
        "temp_df = temp_transformer.transform(X_train.head())\n",
        "numerical_features_after_fe = temp_df.select_dtypes(include=np.number).columns.drop('id', errors='ignore').tolist()\n",
        "categorical_features_to_encode = [col for col in categorical_features_pre_fe if col != 'school_name']\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[('imputer', base_config['imputer']), ('scaler', base_config['scaler'])])\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]) # Assuming OneHotEncoder\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features_after_fe),\n",
        "        ('cat', categorical_transformer, categorical_features_to_encode)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Definisikan pipeline final untuk tuning\n",
        "pipeline_to_tune = Pipeline(steps=[\n",
        "    ('feature_engineering', SelectableFeatureEngineeringTransformer(include_features=base_config['features'])),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(random_state=42)) # Model to tune\n",
        "])\n",
        "\n",
        "\n",
        "# C. Tentukan Grid Hyperparameter untuk GridSearchCV\n",
        "# Sesuaikan grid ini berdasarkan parameter yang ingin Anda uji untuk GradientBoostingRegressor\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'regressor__max_depth': [3, 5, 7],\n",
        "    'regressor__subsample': [0.8, 0.9, 1.0],\n",
        "    'regressor__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# --- 6. Hyperparameter Tuning dengan GridSearchCV ---\n",
        "print(\"Memulai Hyperparameter Tuning dengan GridSearchCV...\")\n",
        "\n",
        "# Gunakan KFold Cross-Validation\n",
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline_to_tune,\n",
        "    param_grid,\n",
        "    cv=cv_strategy,\n",
        "    scoring='neg_mean_absolute_error', # Menggunakan MAE sebagai metrik\n",
        "    n_jobs=-1, # Gunakan semua core CPU\n",
        "    verbose=2 # Tampilkan detail proses\n",
        ")\n",
        "\n",
        "# Lakukan tuning pada SELURUH data training yang sudah dibersihkan targetnya\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Tuning GridSearchCV selesai.\")\n",
        "print(f\"MAE terbaik dari CV: {-grid_search.best_score_:.4f}\") # Negate score to get positive MAE\n",
        "print(\"Parameter terbaik:\", grid_search.best_params_)\n",
        "\n",
        "# --- 7. Melatih Model Final & Membuat Prediksi ---\n",
        "print(\"\\nMelatih model final dengan parameter terbaik...\")\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Latih model terbaik pada SELURUH data training\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Membuat prediksi pada data test...\")\n",
        "final_predictions = best_model.predict(X_test)\n",
        "\n",
        "# --- 8. Membuat File Submission ---\n",
        "submission_df = pd.DataFrame({'id': X_test['id'], 'dropout_rate_percent': final_predictions})\n",
        "submission_df.to_csv('submission_gridsearch_tuned.csv', index=False)\n",
        "\n",
        "print(\"\\n========================================================\")\n",
        "print(\"File 'submission_gridsearch_tuned.csv' berhasil dibuat dari model hasil tuning GridSearchCV.\")\n",
        "print(\"========================================================\")"
      ],
      "metadata": {
        "id": "-lHs0qo1eqf8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}